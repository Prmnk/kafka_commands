sqoop-list-databases --connect "jdbc:mysql://ms.itversity.com:3306" --username retail_user --password itversity

-- If noo db, then default db
sqoop-list-tables --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity

sqoop-eval --connect "jdbc:mysql://ms.itversity.com:3306" --username retail_user --password itversity --query "Select * from retail_db.customers limit 10"

-- With primary key - no of folder  = number of mapper
sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/queryresult

--- define number of mappers
sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/queryresult2 --m 2

--compression
sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/queryresult3 --m 4 --compression-codec BZip2Codec


 
sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/ordercustom --m 4 --compression-codec BZip2Codec --columns order_id, order_status --where "order_status in ('complete','closed')"

sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/ordercustom --m 4 --compression-codec BZip2Codec --columns order_id,order_status --where "order_status in ('complete','closed')" --boundary-query "Select 1, 1000"

--- add below to split on different col
-Dorg.apache.sqoop.splitter.allow_text_splitter=true
--split_by col_name

---- Or use one mapper
--autoreset-to-one-mapper

---in case target directoty exists and we need to overwrite it
--delete-target-dir


--- to append new data on existing directory
sqoop-import --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --target-dir home/itv000053/ordercustomd1 --m 4 --compression-codec BZip2Codec --columns order_id,order_status  --boundary-query "Select 1, 2000" --append

---- NULL ( like COALESCE) replace NULLs with specified value
--null-non-string "-1"
--null-string " "


-----------incremental import (append - insert /last modified - upsert)
--check-column order_id
--incremental append
--last-value (last/max value of the records present in table) -----needs tracking for next run


--check-column order_date
--incremental lastmodified
--last-value TimeStamp -----needs tracking for next run
--merge-key order_id (Primary key, to keep only one record) [Or --append in case we need to keep duplicates]


------------------export
sqoop-export --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --export-dir home/itv000053/file_name.csv --fields-terminated-by ','


-- for failure handling add staging table with same schema as target table - if successful in stage, moved to original table
sqoop-export --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" --username retail_user --password itversity --table orders --export-dir -- staging-table orders_stage home/itv000053/file_name.csv --fields-terminated-by ','



---------------------- job
sqoop job --show job_name

sqoop job -- exec job_name

password ecnryption - then provide password alias 
